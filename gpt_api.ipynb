{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.28.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.20->openai) (3.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key=\"************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8F6ICntiLhtlVSBj4jVnIeW1klzN6\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698609800,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Pi is an irrational number with a value of approximately 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 14,\n",
      "    \"completion_tokens\": 48,\n",
      "    \"total_tokens\": 62\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\",\"content\": \"what's the value of Pi \"}]\n",
    "\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is an irrational number with a value of approximately 3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679.\n"
     ]
    }
   ],
   "source": [
    "print(completion['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_content=completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users input was what's the value of Pi, round it it 2 points\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "user_input  = input(\">: \")\n",
    "print(\"users input was\",user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message_history\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of π (Pi) rounded to two decimal places is approximately 3.14.\n"
     ]
    }
   ],
   "source": [
    "reply_content=completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"assistant\", \"content\": reply_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"what's the value of Pi, round it it 2 points\"}, {'role': 'assistant', 'content': 'The value of π (Pi) rounded to two decimal places is approximately 3.14.'}]\n"
     ]
    }
   ],
   "source": [
    "print(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input was: who dicoverd this value\n",
      "\n",
      "I apologize, but as an AI language model, I am unable to directly access or manipulate user input. My purpose is to provide information and assist with questions to the best of my abilities. If you have any specific queries or need assistance with anything, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "user_input=input(\">:\")\n",
    "print(\"User input was:\",user_input)\n",
    "print()\n",
    "message_history.append({\"role\":\"user\",\"content\":\"user_input\"})\n",
    "\n",
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message_history\n",
    ")\n",
    "\n",
    "reply_content=completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input : what is 2*3\n",
      "\n",
      "2 multiplied by 3 equals 6.\n",
      "\n",
      "User input : what is previous answer. plus 6\n",
      "\n",
      "The previous answer is 6. When we add 6 to it, we get 12.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All Together\n",
    "\n",
    "message_history = []\n",
    "\n",
    "def chat(inp,role = \"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": inp})\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=message_history\n",
    "    )\n",
    "\n",
    "    reply_content=completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\":\"assistant\",\"content\":\"reply_content\"})\n",
    "    return reply_content\n",
    "\n",
    "for i in range(2):\n",
    "    user_input=input(\">: \")\n",
    "    print(\"User input :\",user_input)\n",
    "    print()\n",
    "    chat(user_input)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/tmyxs31x00db0j92sp084dhm0000gn/T/ipykernel_10143/3900444583.py:21: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  txt=gr.Textbox(show_label=False, placeholder=\"type your messagae here\").style(container=False)\n"
     ]
    }
   ],
   "source": [
    "message_history = [{\"role\": \"user\", \"content\": \" Act as math helper\"},\n",
    "                   {\"role\": \"assistant\",\"content\": f\"OK\"}]\n",
    "\n",
    "def help(input):\n",
    "    global message_history\n",
    "    message_history.append({\"role\": \"user\",\"content\":input})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=message_history\n",
    "    )\n",
    "\n",
    "    reply_content=completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\":\"assistant\",\"content\":reply_content})\n",
    "    response=[(message_history[i][\"content\"],message_history[i+1][\"content\"]) for i in range (2,len(message_history)-1,2 )]\n",
    "    return response\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot=gr.Chatbot() #creaates ibstance\n",
    "    with gr.Row():\n",
    "        txt=gr.Textbox(show_label=False, placeholder=\"type your messagae here\").style(container=False)\n",
    "        txt.submit(help,txt,chatbot)\n",
    "        txt.submit(lambda:\" \",None,txt)\n",
    "            # in JS\n",
    "            # txt.submit(None,None,txt, _js=\"() =>{' '}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you with math today?\n",
      "2 multiplied by 3 equals 6.\n",
      "Is there anything else I can help you with?\n",
      "The value of 16 factorial (16!) is calculated by multiplying all positive integers from 1 to 16. \n",
      "\n",
      "16! = 16 x 15 x 14 x 13 x 12 x 11 x 10 x 9 x 8 x 7 x 6 x 5 x 4 x 3 x 2 x 1\n",
      "\n",
      "The value of 16! is approximately 20,922,789,888,000.\n",
      "\n",
      "Is there anything else I can assist you with?\n",
      "Alright! If you have any math-related questions in the future, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
